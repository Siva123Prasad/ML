{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9f15d8-b032-4d20-b658-4545f0a87612",
   "metadata": {},
   "source": [
    "# Post 20: Measuring the Impact of Personalization (Causal Inference)\n",
    "\n",
    "## The Problem\n",
    "\n",
    "The personalization team is celebrating.\n",
    "\n",
    "They rolled out dynamic homepage content to 50% of users (A/B test). Results are in:\n",
    "- Control: 16.5% purchase rate\n",
    "- Treatment: 25.4% purchase rate  \n",
    "- **Lift: 54.3%**\n",
    "\n",
    "The VP of Product wants to scale to 100% of users.\n",
    "\n",
    "But the CPO asks a hard question:\n",
    "\n",
    "**\"Does personalization CAUSE more purchases—or do engaged users just buy more anyway?\"**\n",
    "\n",
    "This is the difference between **correlation and causation**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "### The Selection Bias Problem\n",
    "\n",
    "When you look closer:\n",
    "- Treatment group average engagement: 0.294\n",
    "- Control group average engagement: 0.274\n",
    "\n",
    "**Treatment group is MORE ENGAGED to begin with!**\n",
    "\n",
    "Why? Because personalization was rolled out to:\n",
    "- Users who logged in more frequently\n",
    "- Users with higher past purchase history  \n",
    "- Power users on desktop\n",
    "\n",
    "**High engagement users:**\n",
    "- More likely to receive personalization (selection bias)\n",
    "- More likely to purchase ANYWAY (confounding)\n",
    "\n",
    "So that 54.3% lift includes:\n",
    "1. TRUE causal effect of personalization\n",
    "2. BIAS from engaged users buying more regardless\n",
    "\n",
    "**Question: How much of the 54.3% is real?**\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution: Causal Inference\n",
    "\n",
    "### What is Causal Inference?\n",
    "\n",
    "Moving from \"correlation\" (things happen together) to \"causation\" (one thing CAUSES another).\n",
    "\n",
    "**Techniques:**\n",
    "- Randomized Controlled Trials (RCTs) - gold standard but expensive\n",
    "- **Propensity Score Matching** - what we'll use\n",
    "- Regression Discontinuity\n",
    "- Difference-in-Differences\n",
    "- Instrumental Variables\n",
    "\n",
    "---\n",
    "\n",
    "## Propensity Score Matching (Step-by-Step)\n",
    "\n",
    "### Step 1: Identify Confounders\n",
    "\n",
    "Variables that affect BOTH treatment assignment AND outcome:\n",
    "- **Engagement score** - engaged users get personalization AND buy more\n",
    "- **Past purchases** - repeat buyers get personalization AND buy again\n",
    "- **Account age** - tenured users see personalization AND are loyal\n",
    "- **Device type** - desktop users get personalization AND convert better\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Estimate Propensity Scores\n",
    "\n",
    "**Propensity score = probability of receiving treatment given confounders**\n",
    "\n",
    "Train logistic regression:\n",
    "P(Treatment = 1 | engagement, past_purchases, account_age, device)\n",
    "\n",
    "Each customer gets a score (0-1):\n",
    "- High score = likely to receive personalization\n",
    "- Low score = unlikely to receive personalization\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Match Treatment to Control\n",
    "\n",
    "For each treatment customer, find a control customer with:\n",
    "- Similar propensity score\n",
    "- Similar engagement\n",
    "- Similar past behavior\n",
    "- Similar demographics\n",
    "\n",
    "**Result: Balanced groups**\n",
    "\n",
    "Before matching:\n",
    "- Treatment engagement: 0.294\n",
    "- Control engagement: 0.274  \n",
    "- **Difference: 0.020** (biased!)\n",
    "\n",
    "After matching:\n",
    "- Treatment engagement: 0.294\n",
    "- Control engagement: 0.293  \n",
    "- **Difference: 0.0003** (balanced!)\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Calculate Average Treatment Effect (ATE)\n",
    "\n",
    "Compare matched groups:\n",
    "- Control purchase rate: 16.7%\n",
    "- Treatment purchase rate: 25.4%  \n",
    "- **ATE: 8.68 percentage points**\n",
    "- **Relative lift: 52.0%**\n",
    "\n",
    "This is the TRUE causal effect.\n",
    "\n",
    "---\n",
    "\n",
    "## Naive vs Causal Comparison\n",
    "\n",
    "| Method | Control | Treatment | Lift | Why? |\n",
    "|--------|---------|-----------|------|------|\n",
    "| **Naive** | 16.5% | 25.4% | 54.3% | Includes selection bias |\n",
    "| **Causal (Matched)** | 16.7% | 25.4% | 52.0% | TRUE incremental effect |\n",
    "\n",
    "**Difference: 2.3 percentage points due to confounding!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b4d319-da87-4a77-9d8f-bba1fee4b9cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POST 20: MEASURING THE IMPACT OF PERSONALIZATION\n",
      "Causal Inference with Propensity Score Matching\n",
      "======================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "Total Customers: 10,000\n",
      "Treatment (Personalization): 5,520\n",
      "Control (No Personalization): 4,480\n",
      "\n",
      "======================================================================\n",
      "STEP 1: NAIVE ANALYSIS (CORRELATION, NOT CAUSATION)\n",
      "======================================================================\n",
      "\n",
      "Purchase Rates:\n",
      "  Control: 16.45%\n",
      "  Treatment: 25.38%\n",
      "  Naive Lift: 54.28%\n",
      "\n",
      "Problem: Selection Bias!\n",
      "  Treatment group engagement: 0.294\n",
      "  Control group engagement: 0.274\n",
      "  → Treatment group more engaged (confounded!)\n",
      "\n",
      "======================================================================\n",
      "STEP 2: PROPENSITY SCORE MATCHING (CAUSAL INFERENCE)\n",
      "======================================================================\n",
      "\n",
      "Propensity scores estimated!\n",
      "Propensity score range: 0.469 to 0.666\n",
      "Mean propensity score: 0.552\n",
      "\n",
      "======================================================================\n",
      "STEP 3: PROPENSITY SCORE MATCHING (1:1)\n",
      "======================================================================\n",
      "\n",
      "Matching complete!\n",
      "Matched pairs: 5,520\n",
      "\n",
      "Balance Check (After Matching):\n",
      "  Engagement - Treatment: 0.294\n",
      "  Engagement - Control: 0.293\n",
      "  Difference: 0.0003\n",
      "\n",
      "======================================================================\n",
      "STEP 4: AVERAGE TREATMENT EFFECT (ATE)\n",
      "======================================================================\n",
      "\n",
      "Causal Effect (After Matching):\n",
      "  Control purchase rate: 16.70%\n",
      "  Treatment purchase rate: 25.38%\n",
      "  Average Treatment Effect (ATE): 8.68 percentage points\n",
      "  Relative Lift: 51.95%\n",
      "\n",
      "Statistical Significance:\n",
      "  T-statistic: 11.247\n",
      "  P-value: 0.0000\n",
      "  Significant: Yes (α=0.05)\n",
      "\n",
      "======================================================================\n",
      "STEP 5: NAIVE VS CAUSAL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "          Method  Control_Rate  Treatment_Rate    Lift_%\n",
      "  Naive (Biased)     16.450893       25.380435 54.279983\n",
      "Causal (Matched)     16.702899       25.380435 51.952278\n",
      "\n",
      "Key Insight:\n",
      "  Naive analysis: 54.3% lift (WRONG - includes selection bias)\n",
      "  Causal analysis: 52.0% lift (CORRECT - true incremental effect)\n",
      "  Difference: 2.3 percentage points due to confounding!\n",
      "\n",
      "======================================================================\n",
      "STEP 6: BUSINESS IMPACT (REVENUE)\n",
      "======================================================================\n",
      "\n",
      "Revenue Impact:\n",
      "  Control (avg revenue/customer): $18.38\n",
      "  Treatment (avg revenue/customer): $28.05\n",
      "  Incremental revenue (ATE): $9.67/customer\n",
      "\n",
      "Projected Impact (1M customers, 50% rollout):\n",
      "  Customers with personalization: 500,000\n",
      "  Incremental revenue: $4,836,289\n",
      "  Annual impact: $4,836,289\n",
      "\n",
      "======================================================================\n",
      "EXPORT RESULTS\n",
      "======================================================================\n",
      "\n",
      "Results exported to 'personalization_causal_analysis.csv'\n",
      "\n",
      "======================================================================\n",
      "COMPLETE CAUSAL INFERENCE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Causal Effect:\n",
      "   Average Treatment Effect: 8.68 percentage points\n",
      "   Relative Lift: 52.0%\n",
      "   P-value: 0.0000 (significant)\n",
      "\n",
      "Business Impact:\n",
      "   Incremental revenue per customer: $9.67\n",
      "   Total incremental revenue (1M customers): $4,836,289\n",
      "\n",
      "Recommendation:\n",
      "   TRUE causal lift: 52.0% (not 54.3%)\n",
      "   Personalization has significant incremental impact\n",
      "   Recommend full rollout to remaining 50% of customers\n",
      "\n",
      "======================================================================\n",
      "POST 20 COMPLETE - CAUSAL INFERENCE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Post 20: Measuring Impact of Personalization\n",
    "# Causal Inference with Propensity Score Matching\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POST 20: MEASURING THE IMPACT OF PERSONALIZATION\")\n",
    "print(\"Causal Inference with Propensity Score Matching\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "personalization_df = pd.read_csv('cdp_personalization_causal.csv')\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Total Customers: {len(personalization_df):,}\")\n",
    "print(f\"Treatment (Personalization): {personalization_df['received_personalization'].sum():,}\")\n",
    "print(f\"Control (No Personalization): {(~personalization_df['received_personalization'].astype(bool)).sum():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: NAIVE ANALYSIS (WRONG - IGNORES CONFOUNDING)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: NAIVE ANALYSIS (CORRELATION, NOT CAUSATION)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "treatment = personalization_df[personalization_df['received_personalization'] == 1]\n",
    "control = personalization_df[personalization_df['received_personalization'] == 0]\n",
    "\n",
    "naive_treatment_rate = treatment['made_purchase'].mean()\n",
    "naive_control_rate = control['made_purchase'].mean()\n",
    "naive_lift = (naive_treatment_rate - naive_control_rate) / naive_control_rate\n",
    "\n",
    "print(f\"\\nPurchase Rates:\")\n",
    "print(f\"  Control: {naive_control_rate*100:.2f}%\")\n",
    "print(f\"  Treatment: {naive_treatment_rate*100:.2f}%\")\n",
    "print(f\"  Naive Lift: {naive_lift*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nProblem: Selection Bias!\")\n",
    "print(f\"  Treatment group engagement: {treatment['engagement_score'].mean():.3f}\")\n",
    "print(f\"  Control group engagement: {control['engagement_score'].mean():.3f}\")\n",
    "print(f\"  → Treatment group more engaged (confounded!)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: PROPENSITY SCORE ESTIMATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PROPENSITY SCORE MATCHING (CAUSAL INFERENCE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Encode device type\n",
    "personalization_df['device_mobile'] = (personalization_df['device_type'] == 'Mobile').astype(int)\n",
    "personalization_df['device_desktop'] = (personalization_df['device_type'] == 'Desktop').astype(int)\n",
    "\n",
    "# Features that predict treatment assignment (confounders)\n",
    "confounder_cols = ['engagement_score', 'past_purchases', 'account_age_days', \n",
    "                   'device_mobile', 'device_desktop']\n",
    "\n",
    "X = personalization_df[confounder_cols]\n",
    "y_treatment = personalization_df['received_personalization']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Estimate propensity scores (probability of receiving treatment)\n",
    "propensity_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "propensity_model.fit(X_scaled, y_treatment)\n",
    "\n",
    "propensity_scores = propensity_model.predict_proba(X_scaled)[:, 1]\n",
    "personalization_df['propensity_score'] = propensity_scores\n",
    "\n",
    "print(f\"\\nPropensity scores estimated!\")\n",
    "print(f\"Propensity score range: {propensity_scores.min():.3f} to {propensity_scores.max():.3f}\")\n",
    "print(f\"Mean propensity score: {propensity_scores.mean():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: MATCHING (1:1 NEAREST NEIGHBOR)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: PROPENSITY SCORE MATCHING (1:1)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate treatment and control\n",
    "treatment_df = personalization_df[personalization_df['received_personalization'] == 1].copy()\n",
    "control_df = personalization_df[personalization_df['received_personalization'] == 0].copy()\n",
    "\n",
    "# Match each treatment to nearest control by propensity score\n",
    "treatment_propensities = treatment_df['propensity_score'].values.reshape(-1, 1)\n",
    "control_propensities = control_df['propensity_score'].values.reshape(-1, 1)\n",
    "\n",
    "# Find nearest neighbors\n",
    "nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "nn.fit(control_propensities)\n",
    "\n",
    "distances, indices = nn.kneighbors(treatment_propensities)\n",
    "\n",
    "# Create matched dataset\n",
    "matched_treatment = treatment_df.copy()\n",
    "matched_control = control_df.iloc[indices.flatten()].copy()\n",
    "\n",
    "print(f\"\\nMatching complete!\")\n",
    "print(f\"Matched pairs: {len(matched_treatment):,}\")\n",
    "\n",
    "# Check balance after matching\n",
    "print(f\"\\nBalance Check (After Matching):\")\n",
    "print(f\"  Engagement - Treatment: {matched_treatment['engagement_score'].mean():.3f}\")\n",
    "print(f\"  Engagement - Control: {matched_control['engagement_score'].mean():.3f}\")\n",
    "print(f\"  Difference: {abs(matched_treatment['engagement_score'].mean() - matched_control['engagement_score'].mean()):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: ESTIMATE CAUSAL EFFECT (ATE)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: AVERAGE TREATMENT EFFECT (ATE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Purchase rates in matched sample\n",
    "matched_treatment_rate = matched_treatment['made_purchase'].mean()\n",
    "matched_control_rate = matched_control['made_purchase'].mean()\n",
    "\n",
    "# Average Treatment Effect (ATE)\n",
    "ate = matched_treatment_rate - matched_control_rate\n",
    "ate_pct = (ate / matched_control_rate) * 100\n",
    "\n",
    "print(f\"\\nCausal Effect (After Matching):\")\n",
    "print(f\"  Control purchase rate: {matched_control_rate*100:.2f}%\")\n",
    "print(f\"  Treatment purchase rate: {matched_treatment_rate*100:.2f}%\")\n",
    "print(f\"  Average Treatment Effect (ATE): {ate*100:.2f} percentage points\")\n",
    "print(f\"  Relative Lift: {ate_pct:.2f}%\")\n",
    "\n",
    "# Statistical significance\n",
    "t_stat, p_value = stats.ttest_ind(\n",
    "    matched_treatment['made_purchase'],\n",
    "    matched_control['made_purchase']\n",
    ")\n",
    "\n",
    "print(f\"\\nStatistical Significance:\")\n",
    "print(f\"  T-statistic: {t_stat:.3f}\")\n",
    "print(f\"  P-value: {p_value:.4f}\")\n",
    "print(f\"  Significant: {'Yes' if p_value < 0.05 else 'No'} (α=0.05)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: COMPARE NAIVE VS CAUSAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 5: NAIVE VS CAUSAL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['Naive (Biased)', 'Causal (Matched)'],\n",
    "    'Control_Rate': [naive_control_rate*100, matched_control_rate*100],\n",
    "    'Treatment_Rate': [naive_treatment_rate*100, matched_treatment_rate*100],\n",
    "    'Lift_%': [naive_lift*100, ate_pct]\n",
    "})\n",
    "\n",
    "print(f\"\\n{comparison.to_string(index=False)}\")\n",
    "\n",
    "print(f\"\\nKey Insight:\")\n",
    "print(f\"  Naive analysis: {naive_lift*100:.1f}% lift (WRONG - includes selection bias)\")\n",
    "print(f\"  Causal analysis: {ate_pct:.1f}% lift (CORRECT - true incremental effect)\")\n",
    "print(f\"  Difference: {(naive_lift*100 - ate_pct):.1f} percentage points due to confounding!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: REVENUE IMPACT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 6: BUSINESS IMPACT (REVENUE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Revenue analysis\n",
    "treatment_revenue_per_customer = matched_treatment['revenue'].mean()\n",
    "control_revenue_per_customer = matched_control['revenue'].mean()\n",
    "revenue_ate = treatment_revenue_per_customer - control_revenue_per_customer\n",
    "\n",
    "print(f\"\\nRevenue Impact:\")\n",
    "print(f\"  Control (avg revenue/customer): ${control_revenue_per_customer:.2f}\")\n",
    "print(f\"  Treatment (avg revenue/customer): ${treatment_revenue_per_customer:.2f}\")\n",
    "print(f\"  Incremental revenue (ATE): ${revenue_ate:.2f}/customer\")\n",
    "\n",
    "# Scale to full customer base\n",
    "total_customers = 1000000  # 1M customers\n",
    "personalization_rollout_pct = 0.50  # 50% get personalization\n",
    "\n",
    "customers_with_personalization = int(total_customers * personalization_rollout_pct)\n",
    "incremental_revenue_total = customers_with_personalization * revenue_ate\n",
    "\n",
    "print(f\"\\nProjected Impact (1M customers, 50% rollout):\")\n",
    "print(f\"  Customers with personalization: {customers_with_personalization:,}\")\n",
    "print(f\"  Incremental revenue: ${incremental_revenue_total:,.0f}\")\n",
    "print(f\"  Annual impact: ${incremental_revenue_total:,.0f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPORT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Export matched pairs\n",
    "matched_treatment['match_id'] = range(len(matched_treatment))\n",
    "matched_control['match_id'] = range(len(matched_control))\n",
    "\n",
    "output_df = pd.concat([\n",
    "    matched_treatment[['customer_id', 'propensity_score', 'engagement_score', \n",
    "                      'received_personalization', 'made_purchase', 'revenue', 'match_id']],\n",
    "    matched_control[['customer_id', 'propensity_score', 'engagement_score',\n",
    "                    'received_personalization', 'made_purchase', 'revenue', 'match_id']]\n",
    "])\n",
    "\n",
    "output_df.to_csv('personalization_causal_analysis.csv', index=False)\n",
    "\n",
    "print(f\"\\nResults exported to 'personalization_causal_analysis.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE CAUSAL INFERENCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nCausal Effect:\")\n",
    "print(f\"   Average Treatment Effect: {ate*100:.2f} percentage points\")\n",
    "print(f\"   Relative Lift: {ate_pct:.1f}%\")\n",
    "print(f\"   P-value: {p_value:.4f} ({'significant' if p_value < 0.05 else 'not significant'})\")\n",
    "\n",
    "print(f\"\\nBusiness Impact:\")\n",
    "print(f\"   Incremental revenue per customer: ${revenue_ate:.2f}\")\n",
    "print(f\"   Total incremental revenue (1M customers): ${incremental_revenue_total:,.0f}\")\n",
    "\n",
    "print(f\"\\nRecommendation:\")\n",
    "print(f\"   TRUE causal lift: {ate_pct:.1f}% (not {naive_lift*100:.1f}%)\")\n",
    "print(f\"   Personalization has significant incremental impact\")\n",
    "print(f\"   Recommend full rollout to remaining 50% of customers\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"POST 20 COMPLETE - CAUSAL INFERENCE!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250a4cd-e98c-48c5-beb2-3aadeeed3aaa",
   "metadata": {},
   "source": [
    "\n",
    "## Key Insights\n",
    "\n",
    "### 1. Correlation ≠ Causation\n",
    "\n",
    "Naive analysis: **54.3% lift**  \n",
    "Causal analysis: **52.0% lift**\n",
    "\n",
    "**2.3pp was NOT personalization—it was engaged users buying more.**\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Selection Bias is Real\n",
    "\n",
    "When treatment isn't truly random:\n",
    "- Self-selection (users opt in)\n",
    "- Biased rollout (power users first)\n",
    "- Geographic targeting (rich regions first)\n",
    "\n",
    "**Always check if groups are balanced on confounders.**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Propensity Matching Isolates True Effect\n",
    "\n",
    "By matching similar users:\n",
    "- Remove confounding\n",
    "- Isolate treatment effect\n",
    "- Measure incremental impact\n",
    "\n",
    "**This is what RCTs do—but cheaper.**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Statistical Significance Matters\n",
    "\n",
    "P-value: 0.0000 (highly significant)\n",
    "\n",
    "**Personalization has a real, measurable, statistically significant effect.**\n",
    "\n",
    "Not just noise. Not just chance. TRUE causal impact.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Business Impact is Measurable\n",
    "\n",
    "**Incremental revenue per customer: $9.67**\n",
    "\n",
    "Scale to 1M customers (50% rollout):\n",
    "- 500,000 customers with personalization\n",
    "- **$4.8M annual incremental revenue**\n",
    "\n",
    "This is money you can BANK ON (not inflated by bias).\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters for PMs\n",
    "\n",
    "### You Can't Always Run RCTs\n",
    "\n",
    "Sometimes:\n",
    "- Can't randomize (legacy systems, rollout constraints)\n",
    "- Selection bias already happened (personalization went to engaged users)\n",
    "- Want to measure historical impact (can't re-run experiment)\n",
    "\n",
    "**Causal inference techniques let you measure TRUE impact anyway.**\n",
    "\n",
    "---\n",
    "\n",
    "### Investors Care About Causation\n",
    "\n",
    "CFO: \"You say personalization drove 54% lift. Prove it.\"\n",
    "\n",
    "**Without causal inference:**\n",
    "\"Well, treatment group bought 54% more...\"\n",
    "\"But they were already more engaged...\"\n",
    "\"So maybe it's not all personalization...\"\n",
    "\n",
    "**With causal inference:**\n",
    "\"After controlling for engagement, past purchases, and device type, personalization caused a TRUE 52% lift. P-value < 0.0001. Incremental revenue: $4.8M annually.\"\n",
    "\n",
    "**Which pitch would you fund?**\n",
    "\n",
    "---\n",
    "\n",
    "### Wrong Analysis = Wrong Decisions\n",
    "\n",
    "**Scenario 1: Over-estimate impact**\n",
    "- Think personalization is 54% lift (naive)\n",
    "- TRUE effect is 52%\n",
    "- Roll out expecting $5.4M, get $5.2M\n",
    "- Miss revenue targets\n",
    "\n",
    "**Scenario 2: Under-estimate impact**\n",
    "- Think personalization has no effect (confounders masked it)\n",
    "- TRUE effect is significant\n",
    "- Don't invest, lose $4.8M opportunity\n",
    "\n",
    "**Causal inference = right decisions.**\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Causal Inference\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "1. **A/B tests with selection bias** (like this post)\n",
    "2. **Historical impact measurement** (can't re-run experiment)\n",
    "3. **Observational data** (no randomization)\n",
    "4. **Policy evaluation** (did new feature cause retention?)\n",
    "5. **Marketing attribution** (did campaign cause sales?)\n",
    "\n",
    "### Techniques by Scenario\n",
    "\n",
    "| Scenario | Best Technique |\n",
    "|----------|----------------|\n",
    "| Treatment assignment biased | Propensity Score Matching |\n",
    "| Policy change at threshold | Regression Discontinuity |\n",
    "| Treatment timing varies | Difference-in-Differences |\n",
    "| Natural experiment | Instrumental Variables |\n",
    "| True randomization | Simple A/B test (no need for causal inference) |\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Immediate Actions\n",
    "- Apply propensity matching to past A/B tests\n",
    "- Re-analyze with causal lens (true impact?)\n",
    "- Update revenue projections with TRUE causal effects\n",
    "- Educate stakeholders on correlation vs causation\n",
    "\n",
    "### Advanced Techniques\n",
    "- Uplift modeling (who benefits MOST from treatment?)\n",
    "- Heterogeneous treatment effects (does personalization work differently for segments?)\n",
    "- Causal forests (ML + causation)\n",
    "- Continuous treatment (not binary—dose-response curves)\n",
    "\n",
    "---\n",
    "\n",
    "## PM Takeaways\n",
    "\n",
    "✅ **Correlation ≠ Causation** (always check for confounders)  \n",
    "✅ **Selection bias inflates impact** (naive analysis misleads)  \n",
    "✅ **Propensity matching isolates true effect** (balance groups, measure ATE)  \n",
    "✅ **Statistical significance matters** (p < 0.05 = real effect)  \n",
    "✅ **Causal inference = better decisions** (right investments, right expectations)\n",
    "\n",
    "**The goal:** Move from \"things happened together\" to \"this caused that.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06081693-8a4a-413c-b351-7b5c9a5bb608",
   "metadata": {},
   "source": [
    "## The Final Word\n",
    "\n",
    "You've completed 20 posts on Product Management meets Machine Learning.\n",
    "\n",
    "**Post 20 taught you the most important lesson:**\n",
    "\n",
    "**Not all \"data-driven\" decisions are equally valid.**\n",
    "\n",
    "- Some are correlation (things happen together)\n",
    "- Some are causation (one thing causes another)\n",
    "\n",
    "**Only causation tells you what will happen if you ACT.**\n",
    "\n",
    "Congrats on finishing the series. You're now equipped to:\n",
    "- Frame product problems as ML problems\n",
    "- Build solutions with real business impact\n",
    "- Measure TRUE incremental value (not inflated estimates)\n",
    "\n",
    "Welcome to the world of ML-powered, causally-informed product management.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6e00d-d2fe-4ff2-8e2c-07db65669ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
