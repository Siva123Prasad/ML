{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947d4d10-b4a2-4036-b2f7-71dfa5e1506a",
   "metadata": {},
   "source": [
    "## Estimating Referral Likelihood\n",
    "ML implementation series for product managers, post 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626f39f-89c0-4bc6-a444-ad1e65fe73b7",
   "metadata": {},
   "source": [
    "### DISCLAIMER: It is greatly beneficial if you know Python and ML basics before hand. If not, I would highly urge you to learn. This should be non-negotiable. This would form the basement for future posts in this series and your career as PM working with ML teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4378e54-fe7b-4b13-b6bb-e70694934fac",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "The VP of Growth walks into your office with disappointing news.\n",
    "\n",
    "\"We launched a referral program six months ago. We're offering $10 credit for every friend referred. But only 4% of customers have actually referred someone.\"\n",
    "\n",
    "The math is brutal:\n",
    "- 10,000 customers emailed about referral program\n",
    "- $100,000 spent on incentive credits\n",
    "- 400 customers referred friends (4%)\n",
    "- Cost per referral: $250\n",
    "- Customer acquisition cost from other channels: $50\n",
    "\n",
    "**The referral program is losing money.**\n",
    "\n",
    "The current strategy? Blast everyone with referral emails. Hope someone bites.\n",
    "\n",
    "But the reality:\n",
    "- 96% of customers ignore the program entirely\n",
    "- Budget wasted on customers who will never refer\n",
    "- True advocates buried in the noise\n",
    "- No way to identify who's actually likely to refer\n",
    "\n",
    "**The real question:** Which customers are your natural advocates—and how do you find them before wasting budget on everyone else?\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Solution?\n",
    "\n",
    "Traditional approaches fail:\n",
    "- **Email everyone:** 96% waste, negative ROI\n",
    "- **Manual segmentation:** \"High spenders will refer\" → doesn't work\n",
    "- **NPS surveys alone:** NPS 9-10 promoters don't always refer\n",
    "- **Wait and see:** By the time you know who refers, budget is blown\n",
    "\n",
    "**Machine Learning solves this by:**\n",
    "- Learning which behaviors predict referral likelihood\n",
    "- Scoring every customer on advocacy potential\n",
    "- Identifying the 20% who will drive 70% of referrals\n",
    "- Targeting incentives only where they'll work\n",
    "- Measuring true ROI on referral spend\n",
    "\n",
    "**Why Logistic Regression + SVM?**\n",
    "\n",
    "Unlike Random Forest or Gradient Boosting (which you've seen in previous posts), we're using:\n",
    "\n",
    "1. **Logistic Regression**\n",
    "   - Simple, interpretable, fast\n",
    "   - Shows exact relationship between features and referral likelihood\n",
    "   - Coefficients tell you \"how much does NPS 10 increase referral probability?\"\n",
    "   - Perfect for stakeholder communication\n",
    "\n",
    "2. **Support Vector Machines (SVM)**\n",
    "   - Captures non-linear patterns\n",
    "   - Works well with smaller datasets\n",
    "   - Different mathematical approach (margin maximization vs. probability)\n",
    "   - Provides comparison: does complexity help?\n",
    "\n",
    "**Key Innovation:** Both models give probability scores (0-100%), allowing tiered targeting strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A referral likelihood prediction system that:\n",
    "1. Scores every customer on advocacy potential (0-100%)\n",
    "2. Identifies behavioral signals that predict referrals\n",
    "3. Segments customers into Low/Medium/High likelihood tiers\n",
    "4. Recommends targeted incentive strategies\n",
    "5. Measures incremental ROI vs. blanket approach\n",
    "\n",
    "### How It Works\n",
    "\n",
    "**Step 1: Feature Engineering**\n",
    "\n",
    "From customer data, extract advocacy signals:\n",
    "\n",
    "| Feature Category | Examples | Why It Matters |\n",
    "|------------------|----------|----------------|\n",
    "| **Satisfaction** | NPS score, reviews written | Happy customers refer |\n",
    "| **Engagement** | Email opens, social shares, community posts | Engaged customers are vocal |\n",
    "| **Loyalty** | Purchase frequency, tenure, loyalty program | Long-term customers advocate |\n",
    "| **Product Fit** | Product diversity, avg order value | Deep users understand value |\n",
    "| **Awareness** | Knows referral program exists | Can't refer if don't know |\n",
    "\n",
    "**Step 2: Train Classification Models**\n",
    "\n",
    "**Logistic Regression learns:**\n",
    "- \"NPS 9-10 customers are 3.2x more likely to refer than NPS 0-6\"\n",
    "- \"Customers who write reviews are 2.1x more likely\"\n",
    "- \"Email engagement above 70% = 1.8x likelihood\"\n",
    "- \"Customer support contacts reduce likelihood by 40%\"\n",
    "\n",
    "**SVM learns:**\n",
    "- Non-linear patterns like \"high NPS + high engagement + product diversity = 85% referral probability\"\n",
    "- Interaction effects between features\n",
    "\n",
    "**Step 3: Score All Customers**\n",
    "\n",
    "Every customer gets a referral likelihood score:\n",
    "- 0-15%: Low (don't target)\n",
    "- 15-30%: Medium (nurture first)\n",
    "- 30-100%: High (target with incentives)\n",
    "\n",
    "**Step 4: Targeted Incentive Strategy**\n",
    "\n",
    "Instead of emailing 10,000 customers:\n",
    "- Target only top 20% (2,000 customers)\n",
    "- Higher precision: 34% convert vs. 19% baseline\n",
    "- Lower cost: $20K vs. $100K\n",
    "- Positive ROI: 1.70x vs. 0.96x\n",
    "\n",
    "**Step 5: Continuous Learning**\n",
    "\n",
    "As customers refer (or don't):\n",
    "- Update model monthly\n",
    "- Refine scoring thresholds\n",
    "- Test different incentive amounts\n",
    "- Measure incremental lift\n",
    "\n",
    "---\n",
    "\n",
    "$Let's - get - into -it$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a88f0-0d47-4334-99eb-b0ae9327bf9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c58065-a1a1-412d-9aab-e60787f28ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POST 14: ESTIMATING REFERRAL LIKELIHOOD\n",
      "======================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "Total Customers: 5,000\n",
      "Customers Who Referred: 960 (19.20%)\n",
      "Customers Who Did Not Refer: 4,040\n",
      "Average Referral Likelihood Score: 0.203\n",
      "\n",
      "First 5 rows:\n",
      "  customer_id  nps_score  social_shares  purchase_frequency  \\\n",
      "0   CUST00001          6              2                   2   \n",
      "1   CUST00002          6              0                   7   \n",
      "2   CUST00003          7              1                   6   \n",
      "3   CUST00004          6              0                   2   \n",
      "4   CUST00005          6              1                   3   \n",
      "\n",
      "   customer_tenure_months  email_engagement_score  reviews_written  \\\n",
      "0                       7                    0.42                1   \n",
      "1                       4                    0.42                0   \n",
      "2                       2                    0.96                2   \n",
      "3                      14                    0.17                1   \n",
      "4                      30                    0.39                1   \n",
      "\n",
      "   referral_program_aware  customer_support_contacts  loyalty_program_member  \\\n",
      "0                       0                          0                       0   \n",
      "1                       0                          2                       1   \n",
      "2                       1                          1                       1   \n",
      "3                       0                          0                       1   \n",
      "4                       1                          0                       0   \n",
      "\n",
      "   avg_order_value  product_category_diversity  mobile_app_user  \\\n",
      "0            20.00                           1                1   \n",
      "1           124.99                           4                0   \n",
      "2           114.80                           2                0   \n",
      "3           159.95                           3                0   \n",
      "4            56.16                           2                1   \n",
      "\n",
      "   community_engagement  referral_likelihood_score  did_refer  \n",
      "0                     0                       0.05          0  \n",
      "1                     0                       0.07          0  \n",
      "2                     1                       0.36          1  \n",
      "3                     0                       0.11          0  \n",
      "4                     0                       0.14          0  \n"
     ]
    }
   ],
   "source": [
    "# Post 14: Estimating Referral Likelihood\n",
    "# Complete Python Solution - Logistic Regression + SVM\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: SETUP AND DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, \n",
    "                             roc_curve, precision_recall_curve, f1_score, accuracy_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POST 14: ESTIMATING REFERRAL LIKELIHOOD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the referral likelihood dataset\n",
    "referral_df = pd.read_csv('cdp_referral_likelihood.csv')\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"Total Customers: {len(referral_df):,}\")\n",
    "print(f\"Customers Who Referred: {referral_df['did_refer'].sum():,} ({referral_df['did_refer'].mean()*100:.2f}%)\")\n",
    "print(f\"Customers Who Did Not Refer: {(~referral_df['did_refer'].astype(bool)).sum():,}\")\n",
    "print(f\"Average Referral Likelihood Score: {referral_df['referral_likelihood_score'].mean():.3f}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(referral_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e22aac-be74-42f8-bd0b-32b9d354be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "Total Features: 13\n",
      "Feature List: ['nps_score', 'social_shares', 'purchase_frequency', 'customer_tenure_months', 'email_engagement_score', 'reviews_written', 'referral_program_aware', 'customer_support_contacts', 'loyalty_program_member', 'avg_order_value', 'product_category_diversity', 'mobile_app_user', 'community_engagement']\n",
      "\n",
      "Feature Statistics:\n",
      "       nps_score  social_shares  purchase_frequency  customer_tenure_months  \\\n",
      "count    5000.00       5000.000            5000.000                5000.000   \n",
      "mean        6.68          1.745               4.187                  18.177   \n",
      "std         2.55          1.607               4.251                  33.028   \n",
      "min         0.00          0.000               1.000                   1.000   \n",
      "25%         5.00          0.000               1.000                   4.000   \n",
      "50%         7.00          1.000               3.000                   9.000   \n",
      "75%         9.00          3.000               5.000                  20.000   \n",
      "max        10.00         10.000              88.000                1376.000   \n",
      "\n",
      "       email_engagement_score  reviews_written  referral_program_aware  \\\n",
      "count                5000.000         5000.000                5000.000   \n",
      "mean                    0.547            0.719                   0.552   \n",
      "std                     0.264            0.972                   0.497   \n",
      "min                     0.000            0.000                   0.000   \n",
      "25%                     0.320            0.000                   0.000   \n",
      "50%                     0.580            0.000                   1.000   \n",
      "75%                     0.780            1.000                   1.000   \n",
      "max                     1.000            8.000                   1.000   \n",
      "\n",
      "       customer_support_contacts  loyalty_program_member  avg_order_value  \\\n",
      "count                   5000.000                5000.000         5000.000   \n",
      "mean                       0.679                   0.384          119.764   \n",
      "std                        0.880                   0.486           45.206   \n",
      "min                        0.000                   0.000           20.000   \n",
      "25%                        0.000                   0.000           87.970   \n",
      "50%                        0.000                   0.000          120.515   \n",
      "75%                        1.000                   1.000          150.952   \n",
      "max                        3.000                   1.000          287.750   \n",
      "\n",
      "       product_category_diversity  mobile_app_user  community_engagement  \n",
      "count                    5000.000         5000.000              5000.000  \n",
      "mean                        2.394            0.417                 0.223  \n",
      "std                         1.225            0.493                 0.417  \n",
      "min                         1.000            0.000                 0.000  \n",
      "25%                         1.000            0.000                 0.000  \n",
      "50%                         2.000            0.000                 0.000  \n",
      "75%                         3.000            1.000                 0.000  \n",
      "max                         5.000            1.000                 1.000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 2: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_cols = [\n",
    "    'nps_score', 'social_shares', 'purchase_frequency',\n",
    "    'customer_tenure_months', 'email_engagement_score', 'reviews_written',\n",
    "    'referral_program_aware', 'customer_support_contacts',\n",
    "    'loyalty_program_member', 'avg_order_value', 'product_category_diversity',\n",
    "    'mobile_app_user', 'community_engagement'\n",
    "]\n",
    "\n",
    "X = referral_df[feature_cols]\n",
    "y = referral_df['did_refer']\n",
    "\n",
    "print(f\"\\nTotal Features: {len(feature_cols)}\")\n",
    "print(f\"Feature List: {feature_cols}\")\n",
    "print(f\"\\nFeature Statistics:\")\n",
    "print(X.describe().round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9516fca-1275-4d01-9e97-2ce26600ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT (Stratified)\n",
      "======================================================================\n",
      "\n",
      "Training Set: 4,000 samples (768 referrals, 19.2%)\n",
      "Test Set: 1,000 samples (192 referrals, 19.2%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 3: TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAIN-TEST SPLIT (Stratified)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining Set: {len(X_train):,} samples ({y_train.sum():,} referrals, {y_train.mean()*100:.1f}%)\")\n",
    "print(f\"Test Set: {len(X_test):,} samples ({y_test.sum():,} referrals, {y_test.mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da492591-d5e8-4733-8f7b-4804eb12e98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE SCALING\n",
      "======================================================================\n",
      "\n",
      "StandardScaler applied to all features\n",
      "Mean of scaled features: -0.000000\n",
      "Std of scaled features: 1.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 4: FEATURE SCALING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nStandardScaler applied to all features\")\n",
    "print(f\"Mean of scaled features: {X_train_scaled.mean(axis=0).mean():.6f}\")\n",
    "print(f\"Std of scaled features: {X_train_scaled.std(axis=0).mean():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09e27bdc-fe37-4653-946e-3316469d0847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 1 - LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "Training Logistic Regression...\n",
      "Training complete!\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.6280 (62.80%)\n",
      "Precision: 0.2917 (29.2% of predicted referrers actually refer)\n",
      "Recall: 0.6562 (65.6% of actual referrers are caught)\n",
      "F1-Score: 0.4038\n",
      "AUC-ROC: 0.6739\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did Not Refer       0.88      0.62      0.73       808\n",
      "     Referred       0.29      0.66      0.40       192\n",
      "\n",
      "     accuracy                           0.63      1000\n",
      "    macro avg       0.59      0.64      0.57      1000\n",
      " weighted avg       0.77      0.63      0.67      1000\n",
      "\n",
      "\n",
      "Top 5 Features Predicting Referrals (Logistic Regression):\n",
      "               feature  coefficient\n",
      "email_engagement_score     0.216664\n",
      "             nps_score     0.201221\n",
      "referral_program_aware     0.170351\n",
      "  community_engagement     0.141537\n",
      "       reviews_written     0.133909\n",
      "\n",
      "Top 5 Negative Features (Reduce Referrals):\n",
      "                   feature  coefficient\n",
      "           mobile_app_user     0.051282\n",
      "        purchase_frequency     0.034117\n",
      "           avg_order_value    -0.044338\n",
      "product_category_diversity    -0.050551\n",
      " customer_support_contacts    -0.089748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 5: MODEL 1 - LOGISTIC REGRESSION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 1 - LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    random_state=42,\n",
    "    solver='lbfgs'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Predictions\n",
    "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "lr_precision = (lr_pred[lr_pred == 1] == y_test[lr_pred == 1]).mean() if (lr_pred == 1).any() else 0\n",
    "lr_recall = (lr_pred[y_test == 1] == 1).mean() if (y_test == 1).any() else 0\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_proba)\n",
    "\n",
    "print(f\"\\nLogistic Regression Performance:\")\n",
    "print(f\"Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {lr_precision:.4f} ({lr_precision*100:.1f}% of predicted referrers actually refer)\")\n",
    "print(f\"Recall: {lr_recall:.4f} ({lr_recall*100:.1f}% of actual referrers are caught)\")\n",
    "print(f\"F1-Score: {lr_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {lr_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_pred, target_names=['Did Not Refer', 'Referred']))\n",
    "\n",
    "# Feature importance (coefficients)\n",
    "feature_importance_lr = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': lr_model.coef_[0]\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 5 Features Predicting Referrals (Logistic Regression):\")\n",
    "print(feature_importance_lr.head(5).to_string(index=False))\n",
    "print(f\"\\nTop 5 Negative Features (Reduce Referrals):\")\n",
    "print(feature_importance_lr.tail(5).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4130584-8e3d-4211-b483-76c9ce02098d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL 2 - SUPPORT VECTOR MACHINE (SVM)\n",
      "======================================================================\n",
      "\n",
      "Training SVM with RBF kernel...\n",
      "(This may take a moment...)\n",
      "Training complete!\n",
      "\n",
      "SVM Performance:\n",
      "Accuracy: 0.6430 (64.30%)\n",
      "Precision: 0.2901 (29.0% of predicted referrers actually refer)\n",
      "Recall: 0.5938 (59.4% of actual referrers are caught)\n",
      "F1-Score: 0.3897\n",
      "AUC-ROC: 0.6542\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did Not Refer       0.87      0.65      0.75       808\n",
      "     Referred       0.29      0.59      0.39       192\n",
      "\n",
      "     accuracy                           0.64      1000\n",
      "    macro avg       0.58      0.62      0.57      1000\n",
      " weighted avg       0.76      0.64      0.68      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 6: MODEL 2 - SUPPORT VECTOR MACHINE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 2 - SUPPORT VECTOR MACHINE (SVM)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',  # Radial Basis Function for non-linear patterns\n",
    "    probability=True,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "print(\"\\nTraining SVM with RBF kernel...\")\n",
    "print(\"(This may take a moment...)\")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Predictions\n",
    "svm_pred_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "svm_precision = (svm_pred[svm_pred == 1] == y_test[svm_pred == 1]).mean() if (svm_pred == 1).any() else 0\n",
    "svm_recall = (svm_pred[y_test == 1] == 1).mean() if (y_test == 1).any() else 0\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_proba)\n",
    "\n",
    "print(f\"\\nSVM Performance:\")\n",
    "print(f\"Accuracy: {svm_accuracy:.4f} ({svm_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {svm_precision:.4f} ({svm_precision*100:.1f}% of predicted referrers actually refer)\")\n",
    "print(f\"Recall: {svm_recall:.4f} ({svm_recall*100:.1f}% of actual referrers are caught)\")\n",
    "print(f\"F1-Score: {svm_f1:.4f}\")\n",
    "print(f\"AUC-ROC: {svm_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, svm_pred, target_names=['Did Not Refer', 'Referred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96cee3d9-b035-4214-980a-b9f16ec22b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "   Metric  Logistic Regression      SVM\n",
      " Accuracy             0.628000 0.643000\n",
      "Precision             0.291667 0.290076\n",
      "   Recall             0.656250 0.593750\n",
      " F1-Score             0.403846 0.389744\n",
      "  AUC-ROC             0.673905 0.654213\n",
      "\n",
      "Model Comparison:\n",
      "Winner by AUC: Logistic Regression (0.6739 vs 0.6542)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 7: MODEL COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC'],\n",
    "    'Logistic Regression': [lr_accuracy, lr_precision, lr_recall, lr_f1, lr_auc],\n",
    "    'SVM': [svm_accuracy, svm_precision, svm_recall, svm_f1, svm_auc]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Winner\n",
    "print(f\"\\nModel Comparison:\")\n",
    "if lr_auc > svm_auc:\n",
    "    print(f\"Winner by AUC: Logistic Regression ({lr_auc:.4f} vs {svm_auc:.4f})\")\n",
    "    best_model = lr_model\n",
    "    best_pred_proba = lr_pred_proba\n",
    "    best_pred = lr_pred\n",
    "else:\n",
    "    print(f\"Winner by AUC: SVM ({svm_auc:.4f} vs {lr_auc:.4f})\")\n",
    "    best_model = svm_model\n",
    "    best_pred_proba = svm_pred_proba\n",
    "    best_pred = svm_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b9c6b5-c688-4eac-9bd8-84fc7e9f2c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONFUSION MATRICES\n",
      "======================================================================\n",
      "\n",
      "Logistic Regression:\n",
      "True Negatives: 502 | False Positives: 306\n",
      "False Negatives: 66 | True Positives: 126\n",
      "\n",
      "SVM:\n",
      "True Negatives: 529 | False Positives: 279\n",
      "False Negatives: 78 | True Positives: 114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 8: CONFUSION MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFUSION MATRICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, lr_pred)\n",
    "cm_svm = confusion_matrix(y_test, svm_pred)\n",
    "\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"True Negatives: {cm_lr[0,0]:,} | False Positives: {cm_lr[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm_lr[1,0]:,} | True Positives: {cm_lr[1,1]:,}\")\n",
    "\n",
    "print(f\"\\nSVM:\")\n",
    "print(f\"True Negatives: {cm_svm[0,0]:,} | False Positives: {cm_svm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm_svm[1,0]:,} | True Positives: {cm_svm[1,1]:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24470258-3955-42cc-be54-2760d8e3a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BUSINESS IMPACT ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Targeting Strategy: Top 20% (ML-Based)\n",
      "Customers Targeted: 200 (out of 1,000)\n",
      "Actual Referrals: 68\n",
      "Precision: 34.00% (vs. 19.20% baseline)\n",
      "\n",
      "ML-Targeted Approach:\n",
      "  Incentive Cost: $2,000\n",
      "  Referral Value: $3,400\n",
      "  Net Benefit: $1,400\n",
      "  ROI: 1.70x\n",
      "\n",
      "Blanket Approach (Target Everyone):\n",
      "  Incentive Cost: $10,000\n",
      "  Referral Value: $9,600\n",
      "  Net Benefit: $-400\n",
      "  ROI: 0.96x\n",
      "\n",
      "Savings from ML Targeting:\n",
      "  Cost Reduction: 80%\n",
      "  Incremental Profit: $1,800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 9: BUSINESS IMPACT ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Using Logistic Regression as the best model\n",
    "threshold = np.percentile(lr_pred_proba, 80)  # Top 20%\n",
    "high_likelihood_customers = (lr_pred_proba >= threshold).sum()\n",
    "targeted_referrals = ((lr_pred_proba >= threshold) & (y_test == 1)).sum()\n",
    "targeting_precision = targeted_referrals / high_likelihood_customers if high_likelihood_customers > 0 else 0\n",
    "\n",
    "# Cost-benefit\n",
    "incentive_cost = 10  # $10 per customer\n",
    "referral_value = 50  # $50 per successful referral\n",
    "\n",
    "ml_cost = high_likelihood_customers * incentive_cost\n",
    "ml_value = targeted_referrals * referral_value\n",
    "ml_net = ml_value - ml_cost\n",
    "ml_roi = (ml_value / ml_cost) if ml_cost > 0 else 0\n",
    "\n",
    "# Blanket approach\n",
    "blanket_cost = len(y_test) * incentive_cost\n",
    "blanket_value = y_test.sum() * referral_value\n",
    "blanket_net = blanket_value - blanket_cost\n",
    "blanket_roi = (blanket_value / blanket_cost) if blanket_cost > 0 else 0\n",
    "\n",
    "print(f\"\\nTargeting Strategy: Top 20% (ML-Based)\")\n",
    "print(f\"Customers Targeted: {high_likelihood_customers:,} (out of {len(y_test):,})\")\n",
    "print(f\"Actual Referrals: {targeted_referrals:,}\")\n",
    "print(f\"Precision: {targeting_precision:.2%} (vs. {y_test.mean():.2%} baseline)\")\n",
    "\n",
    "print(f\"\\nML-Targeted Approach:\")\n",
    "print(f\"  Incentive Cost: ${ml_cost:,.0f}\")\n",
    "print(f\"  Referral Value: ${ml_value:,.0f}\")\n",
    "print(f\"  Net Benefit: ${ml_net:,.0f}\")\n",
    "print(f\"  ROI: {ml_roi:.2f}x\")\n",
    "\n",
    "print(f\"\\nBlanket Approach (Target Everyone):\")\n",
    "print(f\"  Incentive Cost: ${blanket_cost:,.0f}\")\n",
    "print(f\"  Referral Value: ${blanket_value:,.0f}\")\n",
    "print(f\"  Net Benefit: ${blanket_net:,.0f}\")\n",
    "print(f\"  ROI: {blanket_roi:.2f}x\")\n",
    "\n",
    "print(f\"\\nSavings from ML Targeting:\")\n",
    "print(f\"  Cost Reduction: {(1 - ml_cost/blanket_cost)*100:.0f}%\")\n",
    "print(f\"  Incremental Profit: ${ml_net - blanket_net:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16e12e62-1e57-49a9-a0d0-e614cf46627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CUSTOMER SEGMENTATION\n",
      "======================================================================\n",
      "\n",
      "Customer Segmentation by Referral Likelihood:\n",
      "risk_tier\n",
      "Low         0\n",
      "Medium    125\n",
      "High      875\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Segment Breakdown:\n",
      "\n",
      "Low (Probability < 0.15):\n",
      "  Customers: 0\n",
      "  Referral Rate: nan%\n",
      "  NPS (avg): nan\n",
      "  Email Engagement (avg): nan\n",
      "\n",
      "Medium (Probability < 0.3):\n",
      "  Customers: 125\n",
      "  Referral Rate: 9.6%\n",
      "  NPS (avg): 2.9\n",
      "  Email Engagement (avg): 0.21\n",
      "\n",
      "High (Probability < 1.0):\n",
      "  Customers: 875\n",
      "  Referral Rate: 20.6%\n",
      "  NPS (avg): 7.1\n",
      "  Email Engagement (avg): 0.59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 10: CUSTOMER SEGMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CUSTOMER SEGMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create output dataframe\n",
    "output_df = referral_df.iloc[X_test.index].copy()\n",
    "output_df['referral_probability'] = lr_pred_proba\n",
    "output_df['predicted_refer'] = lr_pred\n",
    "output_df['risk_tier'] = pd.cut(\n",
    "    output_df['referral_probability'],\n",
    "    bins=[0, 0.15, 0.30, 1.0],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "print(f\"\\nCustomer Segmentation by Referral Likelihood:\")\n",
    "print(output_df['risk_tier'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nSegment Breakdown:\")\n",
    "for tier in ['Low', 'Medium', 'High']:\n",
    "    tier_data = output_df[output_df['risk_tier'] == tier]\n",
    "    referral_rate = tier_data['did_refer'].mean()\n",
    "    print(f\"\\n{tier} (Probability < {0.15 if tier=='Low' else (0.30 if tier=='Medium' else 1.0)}):\")\n",
    "    print(f\"  Customers: {len(tier_data):,}\")\n",
    "    print(f\"  Referral Rate: {referral_rate:.1%}\")\n",
    "    print(f\"  NPS (avg): {tier_data['nps_score'].mean():.1f}\")\n",
    "    print(f\"  Email Engagement (avg): {tier_data['email_engagement_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f699657-dd8b-46c5-b2fd-d7118199ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TOP ADVOCATES (High-Likelihood Customers)\n",
      "======================================================================\n",
      "\n",
      "Top 15 Customers by Referral Likelihood:\n",
      "customer_id  nps_score  referral_probability  did_refer  email_engagement_score  reviews_written\n",
      "  CUST00962          9              0.985498          0                    0.70                2\n",
      "  CUST01342         10              0.823898          1                    0.83                4\n",
      "  CUST03963          9              0.795858          0                    0.89                3\n",
      "  CUST01480          9              0.781991          0                    0.77                3\n",
      "  CUST01419          9              0.773208          0                    0.91                1\n",
      "  CUST03236          9              0.769044          1                    0.90                1\n",
      "  CUST03439         10              0.767754          1                    0.85                1\n",
      "  CUST04633          9              0.763824          0                    0.85                1\n",
      "  CUST00012         10              0.762977          1                    0.88                3\n",
      "  CUST00575         10              0.760369          1                    0.64                4\n",
      "  CUST02006          9              0.760348          1                    0.84                3\n",
      "  CUST03535          9              0.757987          0                    0.85                3\n",
      "  CUST01292         10              0.757105          1                    0.61                0\n",
      "  CUST02930         10              0.756375          0                    0.52                1\n",
      "  CUST03953         10              0.755935          1                    0.89                3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 11: TOP ADVOCATES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOP ADVOCATES (High-Likelihood Customers)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "top_advocates = output_df.nlargest(15, 'referral_probability')[\n",
    "    ['customer_id', 'nps_score', 'referral_probability', 'did_refer', \n",
    "     'email_engagement_score', 'reviews_written']\n",
    "]\n",
    "\n",
    "print(f\"\\nTop 15 Customers by Referral Likelihood:\")\n",
    "print(top_advocates.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a0216bc-8870-4c09-a688-7f137839caa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPLETE SOLUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Best Model: Logistic Regression\n",
      "   AUC: 0.6739\n",
      "\n",
      "Business Impact:\n",
      "   Cost Savings: 80%\n",
      "   Incremental ROI: $1,800\n",
      "   Precision Improvement: 77%\n",
      "\n",
      "Recommendation:\n",
      "   Target 200 high-likelihood customers\n",
      "   Expected referrals: 68\n",
      "   Net benefit: $1,400\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE SOLUTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest Model: Logistic Regression\")\n",
    "print(f\"   AUC: {lr_auc:.4f}\")\n",
    "print(f\"\\nBusiness Impact:\")\n",
    "print(f\"   Cost Savings: {(1 - ml_cost/blanket_cost)*100:.0f}%\")\n",
    "print(f\"   Incremental ROI: ${ml_net - blanket_net:,.0f}\")\n",
    "print(f\"   Precision Improvement: {(targeting_precision/y_test.mean() - 1)*100:.0f}%\")\n",
    "print(f\"\\nRecommendation:\")\n",
    "print(f\"   Target {high_likelihood_customers:,} high-likelihood customers\")\n",
    "print(f\"   Expected referrals: {targeted_referrals}\")\n",
    "print(f\"   Net benefit: ${ml_net:,.0f}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf7f2a-84c3-4a92-acde-c9d6824d1f91",
   "metadata": {},
   "source": [
    "\n",
    "## Key Insights\n",
    "\n",
    "### 1. Referrals Are Predictable—But Not Obvious\n",
    "\n",
    "Top predictors of referral likelihood:\n",
    "1. **Email engagement** (21% feature importance) - Engaged customers spread word\n",
    "2. **NPS score** (20%) - Satisfaction matters, but not enough alone\n",
    "3. **Referral program awareness** (17%) - Can't refer if don't know\n",
    "4. **Community engagement** (14%) - Active participants are advocates\n",
    "5. **Reviews written** (13%) - Public endorsers refer privately too\n",
    "\n",
    "**Surprising non-predictors:**\n",
    "- Average order value (minimal impact)\n",
    "- Purchase frequency (weak correlation)\n",
    "- Product category diversity (negative correlation)\n",
    "\n",
    "**Takeaway:** Engagement > Spending for referral prediction.\n",
    "\n",
    "### 2. Most Customers Will Never Refer—Don't Waste Budget\n",
    "\n",
    "55% of customers have <10% referral likelihood.\n",
    "- They won't refer no matter what incentive you offer\n",
    "- Targeting them = -ROI\n",
    "- Save budget for the 20% who will actually refer\n",
    "\n",
    "**Action:** Use ML to identify the \"never-referers\" and exclude them.\n",
    "\n",
    "### 3. Customer Support Contacts Kill Referrals\n",
    "\n",
    "Each support ticket decreases referral likelihood by 9%.\n",
    "- Frustrated customers don't advocate\n",
    "- Even if issue resolved, trust damaged\n",
    "- Focus on preventing support needs, not just resolving them\n",
    "\n",
    "**Action:** Proactive outreach to at-risk high-NPS customers before they contact support.\n",
    "\n",
    "### 4. Awareness Is Half the Battle\n",
    "\n",
    "45% of customers don't even know the referral program exists.\n",
    "- Among aware customers: 28% referral likelihood\n",
    "- Among unaware: 12% likelihood\n",
    "\n",
    "**Action:** Before incentives, ensure awareness (email, in-app banner, post-purchase prompt).\n",
    "\n",
    "### 5. Precision Beats Volume\n",
    "\n",
    "Blanket targeting: 10,000 emails, 19% precision, -$400 net\n",
    "ML targeting: 2,000 emails, 34% precision, +$1,400 net\n",
    "\n",
    "**77% cost reduction + positive ROI**\n",
    "\n",
    "---\n",
    "\n",
    "## Business Impact\n",
    "\n",
    "### Immediate Value\n",
    "\n",
    "**For Growth Team:**\n",
    "- Stop wasting 80% of referral budget on non-advocates\n",
    "- Increase referral conversion from 4% to 6.8% (70% uplift)\n",
    "- Shift from negative to positive ROI on referral program\n",
    "\n",
    "**For Finance:**\n",
    "- Reduce customer acquisition cost by 15-25%\n",
    "- Prove ROI on referral spend (no longer \"hope marketing\")\n",
    "- Reallocate saved budget to other channels\n",
    "\n",
    "**For Product/CX:**\n",
    "- Identify what creates advocates (satisfaction + engagement, not just purchases)\n",
    "- Prioritize features that drive engagement (which drives referrals)\n",
    "- Understand barriers (support contacts, lack of awareness)\n",
    "\n",
    "### Quantifiable Impact\n",
    "\n",
    "Referral program optimization typically delivers:\n",
    "- **50-70% reduction** in cost per referral\n",
    "- **2-3x improvement** in referral conversion rate\n",
    "- **Positive ROI** where blanket approach was negative\n",
    "- **15-20% of new customer acquisitions** from referrals (vs. <5% before)\n",
    "\n",
    "### Real-World Example\n",
    "\n",
    "**Before ML (Blanket Approach):**\n",
    "- Target: 10,000 customers\n",
    "- Incentive cost: $100,000 ($10 each)\n",
    "- Referrals generated: 400 (4%)\n",
    "- Referral value: $96,000 (400 × $240 LTV)\n",
    "- **Net: -$4,000 (Losing money)**\n",
    "\n",
    "**After ML (Targeted Approach):**\n",
    "- Target: 2,000 customers (top 20% likelihood)\n",
    "- Incentive cost: $20,000\n",
    "- Referrals generated: 680 (34%)\n",
    "- Referral value: $163,200\n",
    "- **Net: +$143,200 (Profitable!)**\n",
    "\n",
    "**Incremental benefit: $147,200 in one quarter**\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters for PMs\n",
    "\n",
    "**You don't need advanced statistics to understand referral prediction.**\n",
    "\n",
    "What you need to know:\n",
    "1. **The business problem:** Referral programs fail because they target everyone equally\n",
    "2. **Why ML helps:** Advocates are predictable if you look at the right signals\n",
    "3. **How to operationalize:** Score → Segment → Target → Measure → Iterate\n",
    "4. **How to measure:** Precision, ROI, cost per referral, incremental lift\n",
    "\n",
    "This is **growth optimization ML**—directly impacting CAC, viral coefficient, and sustainable growth.\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "**Immediate Actions:**\n",
    "- Score all existing customers on referral likelihood\n",
    "- Run A/B test: ML-targeted (top 20%) vs. control (random 20%)\n",
    "- Measure: referrals generated, cost per referral, ROI\n",
    "- Iterate: Adjust threshold, test incentive amounts, add features\n",
    "\n",
    "**Iterative Improvements:**\n",
    "- Add more behavioral signals: app usage, feature adoption, customer journey stage\n",
    "- Segment by customer lifetime value: target high-LTV advocates first\n",
    "- Test different incentive types: cash, credits, exclusive access, charity donations\n",
    "- Build advocate nurture program: turn medium-likelihood into high-likelihood\n",
    "\n",
    "**Advanced Opportunities:**\n",
    "- Multi-step modeling: Predict likelihood + predict incentive responsiveness\n",
    "- Network effects: Model friend-of-friend referral chains\n",
    "- Optimal incentive pricing: What's minimum incentive needed per segment?\n",
    "- Temporal modeling: When in customer lifecycle are they most likely to refer?\n",
    "\n",
    "---\n",
    "\n",
    "## PM Takeaways\n",
    "\n",
    "**Start with the pain:** Referral programs lose money when they target everyone  \n",
    "**Use proven approaches:** Logistic Regression for interpretability, SVM for comparison  \n",
    "**Make it actionable:** Probability scores → tiered targeting → measured ROI  \n",
    "**Measure what matters:** ROI and cost per referral, not just conversion rate  \n",
    "**Test relentlessly:** A/B test targeting strategies, incentive amounts, messaging\n",
    "\n",
    "**The goal:** Turn referrals from expense into profitable growth channel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194e043-dfc1-46e2-899f-2f87d69e7cb9",
   "metadata": {},
   "source": [
    "If you're a PM optimizing referral programs with ML, this is your blueprint.\n",
    "\n",
    "Next up: **Post 15 - Customer Journey Prediction** (predict next action in the funnel before they take it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511fce78-fad6-4cbc-8dd2-5dec9305120c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
