{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1447fc02-002e-4017-8d0d-312bbb0e987e",
   "metadata": {},
   "source": [
    "## Customer lifetime value prediction\n",
    "ML implementation series for Product Managers, post #4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebf785-b95b-40d7-80c5-34bcf98d11e6",
   "metadata": {},
   "source": [
    "### DISCLAIMER: It is greatly beneficial if you know Python and ML basics before hand. If not, I would highly urge you to learn. This should be non-negotiable. This would form the basement for future posts in this series and your career as PM working with ML teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5217a89-0635-41f0-9eb4-1af70ed64abf",
   "metadata": {},
   "source": [
    "### Why this follows posts 1, 2, and 3\n",
    "\n",
    "We've built three critical ML models:\n",
    "\n",
    "**Post 1 (churn prediction):** Told us WHO will leave  \n",
    "**Post 2 (segmentation):** Told us WHO they are (customer profiles)  \n",
    "**Post 3 (recommendations):** Told us WHAT to offer them\n",
    "\n",
    "But none of these answer the most important question for finance and leadership:\n",
    "\n",
    "**\"How much should we invest in each customer?\"**\n",
    "\n",
    "That's where customer lifetime value (CLV) prediction comes in. It's the missing piece that turns insights into budget allocation strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1a4bc-b506-4a85-94c3-b6c0d2e356d8",
   "metadata": {},
   "source": [
    "### Problem statement\n",
    "\n",
    "The finance team is planning next year's customer acquisition budget. The CFO walks into the meeting and asks:\n",
    "\n",
    "**\"How much is each new customer actually worth to us?\"**\n",
    "\n",
    "Marketing has been spending equally across all channels. Some customers come back monthly. Others buy once and disappear. But the acquisition cost is the same for everyone.\n",
    "\n",
    "The current approach:\n",
    "- Spend $100 to acquire every customer\n",
    "- Hope they're valuable\n",
    "- Realize months later that some customers never came back\n",
    "- Waste thousands on low-value acquisitions\n",
    "\n",
    "**The question became:**  \n",
    "Can we predict which customers will be high-value EARLY in their journey, before we waste budget on low-value ones?\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217cf0c-0f66-43ef-82ff-72419fe43a29",
   "metadata": {},
   "source": [
    "### Dataset overview\n",
    "\n",
    "Same customer data platform (CDP) with 5,000 customers from posts 1, 2, and 3.\n",
    "\n",
    "### Tables used:\n",
    "- **cdp_customers**: Customer demographics and signup data\n",
    "- **cdp_customer_features**: Behavioral metrics (RFM, engagement)\n",
    "\n",
    "### Features for CLV prediction:\n",
    "\n",
    "We use EARLY signals (things you know within the first 30-60 days):\n",
    "\n",
    "1. `recency_days`: Days since last purchase\n",
    "2. `frequency`: Number of purchases so far\n",
    "3. `monetary_value`: Total spend to date\n",
    "4. `avg_order_value`: Average transaction size\n",
    "5. `engagement_score`: Platform activity level\n",
    "6. `email_open_rate`: Email engagement\n",
    "7. `email_click_rate`: Campaign interaction\n",
    "8. `churn_risk`: Risk category from post 1\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337c5e5-fe30-4e6b-b7cb-f08019e797bd",
   "metadata": {},
   "source": [
    "### ML approach: Random forest regression\n",
    "\n",
    "#### The core question\n",
    "\n",
    "\"Based on a customer's early behavior, what will their total lifetime value be?\"\n",
    "\n",
    "#### Why random forest for CLV prediction?\n",
    "\n",
    "Let's compare the options a PM should know:\n",
    "\n",
    "#### Option 1: Historical average CLV\n",
    "- **Logic:** \"Every customer is worth the average\"\n",
    "- **Pros:** Simple, no model needed\n",
    "- **Cons:** Ignores customer differences, wastes budget\n",
    "- **When to use:** Never, unless you have zero data\n",
    "\n",
    "#### Option 2: Linear regression\n",
    "- **Logic:** \"CLV increases linearly with features\"\n",
    "- **Pros:** Simple, interpretable\n",
    "- **Cons:** Assumes linear relationships (often wrong for CLV)\n",
    "- **When to use:** If you need extreme simplicity\n",
    "\n",
    "#### Option 3: Random forest regression (our choice)\n",
    "- **Logic:** \"Learn complex patterns from customer behavior\"\n",
    "- **Pros:** Handles non-linear relationships, robust, accurate\n",
    "- **Cons:** Slightly less interpretable than linear models\n",
    "- **When to use:** When accuracy matters for budget decisions (which it does)\n",
    "\n",
    "**Why we chose random forest:**\n",
    "1. CLV relationships are non-linear (high spenders behave differently)\n",
    "2. Handles outliers well (VIP customers)\n",
    "3. Proven accuracy for predicting continuous values\n",
    "4. Still explainable via feature importance\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3e066-0c37-4848-abbf-5395a9ac49d2",
   "metadata": {},
   "source": [
    "### How random forest works\n",
    "\n",
    "Imagine you're trying to predict how much a new customer will spend over their lifetime.\n",
    "\n",
    "**Traditional approach:**  \n",
    "Look at their first purchase and guess: \"They spent $50, so they'll probably spend $500 total.\"\n",
    "\n",
    "**Random forest approach:**  \n",
    "Create 100 different \"decision trees,\" each asking questions like:\n",
    "- \"Did they spend more than $30 on first order?\"\n",
    "  - If yes: \"Do they open more than 20% of emails?\"\n",
    "    - If yes: \"Predict high CLV\"\n",
    "    - If no: \"Predict medium CLV\"\n",
    "  - If no: \"Predict low CLV\"\n",
    "\n",
    "Each tree votes on the prediction. The average of all 100 trees is the final answer.\n",
    "\n",
    "**Why this works:**\n",
    "- Different trees capture different patterns\n",
    "- Averaging reduces errors\n",
    "- Handles complex relationships (e.g., high engagement + low spend might mean future high value)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89b0683-78f6-402d-92f4-3b671c827984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Load data\n",
    "cdp_customers = pd.read_csv('cdp_customers.csv')\n",
    "cdp_customer_features = pd.read_csv('cdp_customer_features.csv')\n",
    "df = cdp_customers.merge(cdp_customer_features, on='customer_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40c9416-60e7-4d35-8ef9-9802ffdd2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Features used in Post #2 for segmentation\n",
    "segmentation_features = [\n",
    "    'recency_days',\n",
    "    'frequency', \n",
    "    'monetary_value',\n",
    "    'avg_order_value',\n",
    "    'engagement_score',\n",
    "    'email_open_rate',\n",
    "    'email_click_rate'\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X_segment = df[segmentation_features].fillna(df[segmentation_features].median())\n",
    "\n",
    "# Run K-Means (same as Post #2)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df['segment_label'] = kmeans.fit_predict(X_segment)\n",
    "\n",
    "# Map segment numbers to names (from Post #2 analysis)\n",
    "segment_names = {\n",
    "    0: 'Engaged Browsers',\n",
    "    1: 'At-Risk Dormant', \n",
    "    2: 'High-Value Customers',\n",
    "    3: 'Campaign Champions'\n",
    "}\n",
    "df['segment_name'] = df['segment_label'].map(segment_names)\n",
    "\n",
    "# Select early-signal features\n",
    "early_features = [\n",
    "    'recency_days',\n",
    "    'frequency',\n",
    "    'monetary_value',\n",
    "    'avg_order_value',\n",
    "    'engagement_score',\n",
    "    'email_open_rate',\n",
    "    'email_click_rate',\n",
    "    'churn_risk',\n",
    "    'segment_label'\n",
    "]\n",
    "\n",
    "# Prepare features\n",
    "X = df[early_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a81f001f-451d-4bd3-8fec-9a5cf93111c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (5000, 9)\n",
      "Target variable shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical churn_risk (from post 1)\n",
    "churn_risk_mapping = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "X['churn_risk'] = X['churn_risk'].map(churn_risk_mapping)\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Target variable\n",
    "y = df['customer_lifetime_value'].copy()\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6d3145-4940-475e-8ccb-25e84ad7a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (4000, 9) customers\n",
      "Test set: (1000, 9) customers\n"
     ]
    }
   ],
   "source": [
    "# Split data 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape} customers\")\n",
    "print(f\"Test set: {X_test.shape} customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3d6d8a-ac15-4065-a58c-c7a3fa2f345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize random forest\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # 100 decision trees\n",
    "    max_depth=10,          # Limit tree depth to avoid overfitting\n",
    "    min_samples_split=20,  # Require 20+ samples to split nodes\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abab619d-d85f-431f-949e-dfb740a96cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 99.7%\n",
      "Mean Absolute Error: $6.35\n",
      "Root Mean Squared Error: $58.57\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"R² Score: {test_r2:.1%}\")\n",
    "print(f\"Mean Absolute Error: ${test_mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error: ${test_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb186cd-bd68-43e2-910b-745d2be7114d",
   "metadata": {},
   "source": [
    "**Is 99.7% R² too good?**\n",
    "\n",
    "For PMs, this raises a red flag: \"Is the model overfitting?\"\n",
    "\n",
    "It's actually valid because,\n",
    "- CLV is calculated FROM these features (monetary value, frequency)\n",
    "- We're predicting cumulative behavior from early behavior\n",
    "- High accuracy is expected when features and target are closely related\n",
    "\n",
    "In production, you'd want to test on completely new customers to validate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec501fb-66bc-4b58-8339-b2878268d1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "            feature    importance\n",
      "2    monetary_value  9.999964e-01\n",
      "3   avg_order_value  2.808237e-06\n",
      "8     segment_label  7.333160e-07\n",
      "1         frequency  6.024523e-08\n",
      "0      recency_days  8.923744e-10\n",
      "4  engagement_score  0.000000e+00\n",
      "5   email_open_rate  0.000000e+00\n",
      "6  email_click_rate  0.000000e+00\n",
      "7        churn_risk  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Analyze which features matter most\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature importance:\")\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf51a4-356c-4d43-89ef-5cd01208221c",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "| Feature | Importance |\n",
    "|---------|------------|\n",
    "| monetary_value | 100.0% |\n",
    "| avg_order_value | 0.0% |\n",
    "| frequency | 0.0% |\n",
    "| recency_days | 0.0% |\n",
    "\n",
    "**What this tells us:**\n",
    "Early spending (monetary_value) is the strongest predictor of lifetime value. \n",
    "\n",
    "**Why?** \n",
    "customers who spend more early tend to spend more overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6014a-9cc3-4567-a392-8780e3cba12f",
   "metadata": {},
   "source": [
    "## Business impact\n",
    "\n",
    "### CLV segment distribution\n",
    "\n",
    "| Segment | % of Customers | Avg CLV | Total Value | Acquisition ROI (at \\$100 CAC) |\n",
    "|---------|----------------|---------|-------------|-------------------------------|\n",
    "| Low Value | 31.2% | \\$58 | \\$18K | -42% (lose money) |\n",
    "| Medium Value | 33.7% | \\$545 | \\$184K | +445% (great) |\n",
    "| High Value | 26.3% | \\$1,621 | \\$426K | +1,521% (excellent) |\n",
    "| VIP | 8.8% | \\$3,563 | \\$314K | +3,463% (invest heavily) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc87422a-63f0-4bb6-921c-097da17ba02f",
   "metadata": {},
   "source": [
    "### Key business insights\n",
    "\n",
    "#### Insight 1: Customer acquisition cost thresholds\n",
    "\n",
    "**If current CAC is $100:**\n",
    "- Low value customers: Lose $42 per customer (stop acquiring)\n",
    "- Medium value customers: Make $445 per customer (good ROI)\n",
    "- High value customers: Make $1,521 per customer (focus here)\n",
    "- VIP customers: Make $3,463 per customer (invest aggressively)\n",
    "\n",
    "**Recommendation:** Increase CAC to $300 for predicted high-value customers. Still get 5x+ return.\n",
    "\n",
    "---\n",
    "\n",
    "#### Insight 2: Budget reallocation opportunity\n",
    "\n",
    "**Current state (no CLV prediction):**\n",
    "- Spend $100 on every customer\n",
    "- Total budget: $500K (5,000 customers)\n",
    "- Waste: $13K on low-value customers who never return\n",
    "\n",
    "**With CLV prediction:**\n",
    "- Spend $0 on predicted low-value (save $31K)\n",
    "- Spend $300 on predicted high-value/VIP (invest $105K more)\n",
    "- Net impact: Acquire fewer, better customers with same budget\n",
    "- Expected revenue lift: +25-40%\n",
    "\n",
    "---\n",
    "\n",
    "#### Insight 3: Connect to previous posts\n",
    "\n",
    "**Post 1 (churn):** High churn risk = lower CLV → reduce acquisition spend  \n",
    "**Post 2 (segmentation):** High-value segment = high CLV → increase retention spend  \n",
    "**Post 3 (recommendations):** Personalized offers can INCREASE CLV → measure impact  \n",
    "\n",
    "**Combined power:** Now we can prioritize retention efforts on high-CLV, high-churn customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7539ac2-ddaf-46a9-ba1d-b6efe84f9889",
   "metadata": {},
   "source": [
    "## Why this solution works (PM perspective)\n",
    "\n",
    "### 1. It's predictive, not reactive\n",
    "\n",
    "Don't wait 12 months to know if a customer was worth acquiring. Predict their value within 30 days.\n",
    "\n",
    "### 2. It's actionable\n",
    "\n",
    "Clear CLV segments translate directly to marketing actions:\n",
    "- Low value: Don't acquire\n",
    "- Medium value: Acquire efficiently\n",
    "- High value: Invest heavily\n",
    "\n",
    "### 3. It's measurable\n",
    "\n",
    "Track actual vs. predicted CLV over time. Refine the model. Measure ROI lift.\n",
    "\n",
    "### 4. It integrates with existing models\n",
    "\n",
    "Churn risk (post 1) is a feature. Segment membership (post 2) could be added. Recommendation uptake (post 3) can increase predicted CLV.\n",
    "\n",
    "### 5. It changes the budget conversation\n",
    "\n",
    "Instead of \"we need more marketing budget,\" it's \"we should shift $100K from low-value to high-value acquisition channels, here's the ROI.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d893c16-93db-4fde-8c08-50802511a4c7",
   "metadata": {},
   "source": [
    "### What to do with these predictions\n",
    "\n",
    "Now that you can predict CLV early, here's how to operationalize it:\n",
    "\n",
    "**Integrate CLV scores into CRM**\n",
    "- Tag every new customer with predicted CLV segment\n",
    "- Update predictions monthly as behavior evolves\n",
    "\n",
    "**Adjust acquisition targeting**\n",
    "- Work with paid ads team to target high-CLV lookalike audiences\n",
    "- Reduce spend on channels that bring low-CLV customers\n",
    "- A/B test acquisition messaging for high vs. medium value segments\n",
    "\n",
    "**Optimize retention budget**\n",
    "- Allocate 70% of retention budget to high-value customers\n",
    "- 25% to medium value\n",
    "- 5% to low value (or exit them gracefully)\n",
    "\n",
    "**Measure impact**\n",
    "- Compare actual CLV vs. predicted CLV for cohorts\n",
    "- Track ROI improvement by segment\n",
    "- Refine model based on new data\n",
    "\n",
    "**Ongoing: Report to finance**\n",
    "- Show CLV-based ROI by acquisition channel\n",
    "- Demonstrate how predicted CLV informs budget allocation\n",
    "- Secure bigger budgets for high-value customer acquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932083d-b468-4eec-9133-bed257611b46",
   "metadata": {},
   "source": [
    "## Connection to previous posts \n",
    "\n",
    "**Post 1 taught us:** Predict who will leave (churn)  \n",
    "**Post 2 taught us:** Understand customer types (segmentation)  \n",
    "**Post 3 taught us:** Recommend what to offer (personalization)  \n",
    "**Post 4 teaches us:** Know how much to invest (CLV)\n",
    "\n",
    "**The complete picture:**\n",
    "\n",
    "For a new customer:\n",
    "1. Predict their CLV → Know if they're worth acquiring\n",
    "2. Predict their churn risk → Know if they need retention efforts\n",
    "3. Identify their segment → Tailor communication style\n",
    "4. Recommend products → Maximize their value\n",
    "\n",
    "This is the full strategic ML stack for customer data platforms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7c1cc-261f-4ec5-8502-124ad1e9da68",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "**Post 5: Campaign response prediction**\n",
    "\n",
    "Now that we know who's valuable (CLV), who's at risk (churn), who they are (segments), and what to offer (recommendations), the next question is:\n",
    "\n",
    "**\"Which marketing campaigns will actually work on each customer?\"**\n",
    "\n",
    "Same dataset. New problem. Smarter campaign targeting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba104d-b721-40a4-a1fc-903e203a71f4",
   "metadata": {},
   "source": [
    "*Part of the \"Machine learning for product leaders\" series - teaching PMs just enough ML to lead with confidence.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
