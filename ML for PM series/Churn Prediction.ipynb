{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8431702f-af74-4955-9fb0-0d5a3a4b8a8e",
   "metadata": {},
   "source": [
    "### DISCLAIMER: It is greatly beneficial if you know Python and ML basics before hand. If not, I would highly urge you to learn. This should be non-negotiable. This would form the basement for future posts in this series and your career as PM working with ML teams. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b1d7a-2c7f-4399-8cd9-19884d1c6de8",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "The retention marketing team has noticed that a significant portion of active customers haven't made repeat purchases in 90 days. The CMO wants to know: \"Which customers are about to churn—and can we stop them before they do?\"\n",
    "\n",
    "The challenge: No one could agree on what \"churn\" actually meant. Was it 60 days of inactivity? 90 days? This is where most ML projects stall—not because of the algorithm, but because of the problem definition. \n",
    "\n",
    "#### Let's now dive into the solution for Problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc35b7c2-68eb-4951-9619-b92d70d70fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING EXISTING CDP DATASETS\n",
      "======================================================================\n",
      "\n",
      "✓ Loaded cdp_customers: (5000, 11)\n",
      "✓ Loaded cdp_customer_features: (5000, 19)\n",
      "✓ Loaded cdp_campaign_responses: (5849, 10)\n",
      "✓ Loaded cdp_support_tickets: (3568, 10)\n",
      "\n",
      "======================================================================\n",
      "CHECKING DATA STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "cdp_customers columns:\n",
      "['customer_id', 'first_name', 'last_name', 'email', 'age', 'gender', 'city', 'state', 'signup_date', 'customer_segment', 'loyalty_tier']\n",
      "\n",
      "First 3 rows:\n",
      "  customer_id first_name  last_name                          email  age  \\\n",
      "0   CUST00001     Robert  Rodriguez  barbara.anderson710@email.com   60   \n",
      "1   CUST00002  Elizabeth     Garcia      anthony.lewis19@email.com   72   \n",
      "2   CUST00003     Donald  Hernandez        john.smith237@email.com   31   \n",
      "\n",
      "  gender       city state signup_date customer_segment loyalty_tier  \n",
      "0      F    Phoenix    OH  2023-02-22          Unknown     Platinum  \n",
      "1      F  Charlotte    TX  2023-02-02          Unknown       Bronze  \n",
      "2  Other    Houston    TX  2020-08-24          Unknown       Silver  \n",
      "\n",
      "\n",
      "cdp_customer_features columns:\n",
      "['customer_id', 'recency_days', 'frequency', 'monetary_value', 'avg_order_value', 'total_events', 'days_since_last_activity', 'page_views', 'product_views', 'cart_adds', 'engagement_score', 'num_support_tickets', 'avg_satisfaction_score', 'campaigns_received', 'email_open_rate', 'email_click_rate', 'campaign_conversions', 'customer_lifetime_value', 'churn_risk']\n",
      "\n",
      "First 3 rows:\n",
      "  customer_id  recency_days  frequency  monetary_value  avg_order_value  \\\n",
      "0   CUST00001         425.0          2          129.10            64.55   \n",
      "1   CUST00002         366.0          4          368.30            92.08   \n",
      "2   CUST00003        1208.0         10         1951.18           195.12   \n",
      "\n",
      "   total_events  days_since_last_activity  page_views  product_views  \\\n",
      "0            30                     290.0          12              3   \n",
      "1            15                     287.0           9              0   \n",
      "2             5                    1318.0           1              0   \n",
      "\n",
      "   cart_adds  engagement_score  num_support_tickets  avg_satisfaction_score  \\\n",
      "0          1              12.5                    0                     NaN   \n",
      "1          2               8.5                    1                     NaN   \n",
      "2          1               2.5                    0                     NaN   \n",
      "\n",
      "   campaigns_received  email_open_rate  email_click_rate  \\\n",
      "0                   5              0.2               0.0   \n",
      "1                   5              0.0               0.0   \n",
      "2                   2              0.5               0.0   \n",
      "\n",
      "   campaign_conversions  customer_lifetime_value churn_risk  \n",
      "0                     0                   129.10     Medium  \n",
      "1                     0                   368.30       High  \n",
      "2                     0                  1951.18       High  \n"
     ]
    }
   ],
   "source": [
    "# Load the existing datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING EXISTING CDP DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load all available datasets\n",
    "cdp_customers = pd.read_csv('cdp_customers.csv')\n",
    "cdp_customer_features = pd.read_csv('cdp_customer_features.csv')\n",
    "cdp_campaign_responses = pd.read_csv('cdp_campaign_responses.csv')\n",
    "cdp_support_tickets = pd.read_csv('cdp_support_tickets.csv')\n",
    "\n",
    "print(\"\\n✓ Loaded cdp_customers:\", cdp_customers.shape)\n",
    "print(\"✓ Loaded cdp_customer_features:\", cdp_customer_features.shape)\n",
    "print(\"✓ Loaded cdp_campaign_responses:\", cdp_campaign_responses.shape)\n",
    "print(\"✓ Loaded cdp_support_tickets:\", cdp_support_tickets.shape)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHECKING DATA STRUCTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\ncdp_customers columns:\")\n",
    "print(cdp_customers.columns.tolist())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(cdp_customers.head(3))\n",
    "\n",
    "print(\"\\n\\ncdp_customer_features columns:\")\n",
    "print(cdp_customer_features.columns.tolist())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(cdp_customer_features.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899130d2-6a06-435e-9caa-12b8de06052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ANALYZING AVAILABLE DATA FOR CHURN PREDICTION\n",
      "======================================================================\n",
      "\n",
      "cdp_campaign_responses columns:\n",
      "['response_id', 'customer_id', 'campaign_name', 'campaign_type', 'sent_date', 'delivered', 'opened', 'clicked', 'converted', 'unsubscribed']\n",
      "\n",
      "First 3 rows:\n",
      "  response_id customer_id                 campaign_name campaign_type  \\\n",
      "0  RESP000001   CUST00001                Welcome Series   Display Ads   \n",
      "1  RESP000002   CUST00001  Product Launch - Electronics         Email   \n",
      "2  RESP000003   CUST00001                Welcome Series         Email   \n",
      "\n",
      "    sent_date  delivered  opened  clicked  converted  unsubscribed  \n",
      "0  2024-05-24       True    True    False      False         False  \n",
      "1  2023-11-29       True   False    False      False         False  \n",
      "2  2024-12-28       True   False    False      False         False  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYZING AVAILABLE DATA FOR CHURN PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check campaign responses for email engagement data\n",
    "print(\"\\ncdp_campaign_responses columns:\")\n",
    "print(cdp_campaign_responses.columns.tolist())\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(cdp_campaign_responses.head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de3e505-bc7b-408e-9a36-9dc90a52ce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING FOR CHURN PREDICTION\n",
      "======================================================================\n",
      "\n",
      "✓ Combined dataset shape: (5000, 29)\n",
      "✓ Columns available: 29\n",
      "\n",
      "✓ Churn distribution:\n",
      "churned\n",
      "1    4165\n",
      "0     835\n",
      "Name: count, dtype: int64\n",
      "  Churn rate: 83.3%\n",
      "\n",
      "✓ Feature matrix shape: (5000, 12)\n",
      "✓ Features used: 12\n",
      "\n",
      "Features:\n",
      "  1. recency_days\n",
      "  2. frequency\n",
      "  3. monetary_value\n",
      "  4. avg_order_value\n",
      "  5. days_since_last_activity\n",
      "  6. engagement_score\n",
      "  7. email_open_rate\n",
      "  8. email_click_rate\n",
      "  9. num_support_tickets\n",
      "  10. campaigns_received\n",
      "  11. campaign_conversions\n",
      "  12. age\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING FOR CHURN PREDICTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Merge customers with features\n",
    "df = cdp_customers.merge(cdp_customer_features, on='customer_id', how='left')\n",
    "\n",
    "print(f\"\\n✓ Combined dataset shape: {df.shape}\")\n",
    "print(f\"✓ Columns available: {len(df.columns)}\")\n",
    "\n",
    "# Create binary churn target variable\n",
    "# Define churn as: High churn risk OR (recency > 90 days AND email_open_rate < 0.2)\n",
    "df['churned'] = ((df['churn_risk'] == 'High') | \n",
    "                 ((df['recency_days'] > 90) & (df['email_open_rate'] < 0.2))).astype(int)\n",
    "\n",
    "print(f\"\\n✓ Churn distribution:\")\n",
    "print(df['churned'].value_counts())\n",
    "print(f\"  Churn rate: {df['churned'].mean():.1%}\")\n",
    "\n",
    "# Select features for the model\n",
    "feature_columns = [\n",
    "    'recency_days',\n",
    "    'frequency',\n",
    "    'monetary_value',\n",
    "    'avg_order_value',\n",
    "    'days_since_last_activity',\n",
    "    'engagement_score',\n",
    "    'email_open_rate',\n",
    "    'email_click_rate',\n",
    "    'num_support_tickets',\n",
    "    'campaigns_received',\n",
    "    'campaign_conversions',\n",
    "    'age'\n",
    "]\n",
    "\n",
    "# Create feature matrix\n",
    "X = df[feature_columns].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Target variable\n",
    "y = df['churned']\n",
    "\n",
    "print(f\"\\n✓ Feature matrix shape: {X.shape}\")\n",
    "print(f\"✓ Features used: {len(feature_columns)}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for i, col in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5ade86-b960-4902-9290-11c062f1ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAIN/TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "✓ Training set: 4000 customers\n",
      "✓ Test set: 1000 customers\n",
      "\n",
      "Train churn rate: 83.3%\n",
      "Test churn rate: 83.3%\n",
      "\n",
      "======================================================================\n",
      "STEP 3: FEATURE SCALING\n",
      "======================================================================\n",
      "\n",
      "✓ Features scaled using StandardScaler\n",
      "✓ Mean = 0, Std = 1 for all features\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training set: {X_train.shape[0]} customers\")\n",
    "print(f\"✓ Test set: {X_test.shape[0]} customers\")\n",
    "print(f\"\\nTrain churn rate: {y_train.mean():.1%}\")\n",
    "print(f\"Test churn rate: {y_test.mean():.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: FEATURE SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n✓ Features scaled using StandardScaler\")\n",
    "print(\"✓ Mean = 0, Std = 1 for all features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c878047a-4097-4f59-a35a-011fcaafba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83c2b6c1-b5ed-4956-8cfc-a81ccd3c86a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL TRAINING - LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "✓ Model trained successfully\n",
      "✓ Algorithm: Logistic Regression\n",
      "✓ Class weights: balanced (to handle imbalanced classes)\n",
      "\n",
      "======================================================================\n",
      "MODEL EVALUATION\n",
      "======================================================================\n",
      "\n",
      " MODEL PERFORMANCE METRICS:\n",
      "----------------------------------------------------------------------\n",
      "  Accuracy:  85.3%\n",
      "  Precision: 98.7%  (Of predicted churners, 98.7% actually churned)\n",
      "  Recall:    83.4%  (We caught 83.4% of all actual churners)\n",
      "  ROC-AUC:   0.933\n",
      "\n",
      " CONFUSION MATRIX:\n",
      "----------------------------------------------------------------------\n",
      "  True Negatives:   158  (Correctly predicted non-churners)\n",
      "  False Positives:    9  (Incorrectly predicted as churners)\n",
      "  False Negatives:  138  (Missed churners)\n",
      "  True Positives:   695  (Correctly predicted churners)\n",
      "\n",
      " CLASSIFICATION REPORT:\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Churned       0.53      0.95      0.68       167\n",
      "     Churned       0.99      0.83      0.90       833\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.76      0.89      0.79      1000\n",
      "weighted avg       0.91      0.85      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL TRAINING - LOGISTIC REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\n✓ Model trained successfully\")\n",
    "print(\"✓ Algorithm: Logistic Regression\")\n",
    "print(\"✓ Class weights: balanced (to handle imbalanced classes)\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\n MODEL PERFORMANCE METRICS:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Accuracy:  {accuracy:.1%}\")\n",
    "print(f\"  Precision: {precision:.1%}  (Of predicted churners, {precision:.1%} actually churned)\")\n",
    "print(f\"  Recall:    {recall:.1%}  (We caught {recall:.1%} of all actual churners)\")\n",
    "print(f\"  ROC-AUC:   {roc_auc:.3f}\")\n",
    "\n",
    "print(\"\\n CONFUSION MATRIX:\")\n",
    "print(\"-\" * 70)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"  True Negatives:  {cm[0,0]:4d}  (Correctly predicted non-churners)\")\n",
    "print(f\"  False Positives: {cm[0,1]:4d}  (Incorrectly predicted as churners)\")\n",
    "print(f\"  False Negatives: {cm[1,0]:4d}  (Missed churners)\")\n",
    "print(f\"  True Positives:  {cm[1,1]:4d}  (Correctly predicted churners)\")\n",
    "\n",
    "print(\"\\n CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 70)\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Churned', 'Churned']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe682199-cc95-4b65-88eb-30f37b312c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      " TOP 10 MOST IMPORTANT FEATURES FOR CHURN PREDICTION:\n",
      "----------------------------------------------------------------------\n",
      "  recency_days                   ↑ increases churn risk (coef:   1.441)\n",
      "  days_since_last_activity       ↑ increases churn risk (coef:   1.051)\n",
      "  engagement_score               ↓ decreases churn risk (coef:  -1.015)\n",
      "  email_open_rate                ↓ decreases churn risk (coef:  -0.757)\n",
      "  frequency                      ↓ decreases churn risk (coef:  -0.323)\n",
      "  campaigns_received             ↑ increases churn risk (coef:   0.127)\n",
      "  email_click_rate               ↓ decreases churn risk (coef:  -0.101)\n",
      "  avg_order_value                ↑ increases churn risk (coef:   0.099)\n",
      "  num_support_tickets            ↓ decreases churn risk (coef:  -0.075)\n",
      "  monetary_value                 ↑ increases churn risk (coef:   0.044)\n",
      "\n",
      "======================================================================\n",
      "BUSINESS INSIGHTS\n",
      "======================================================================\n",
      "\n",
      " KEY INSIGHTS:\n",
      "----------------------------------------------------------------------\n",
      "1. Top 20% of at-risk customers (200 customers):\n",
      "   → 100.0% actually churned\n",
      "   → Marketing can focus on these 200 customers for retention campaigns\n",
      "\n",
      "2. Email engagement is a strong predictor:\n",
      "   → Churned customers: 5.6% email open rate\n",
      "   → Active customers: 16.9% email open rate\n",
      "\n",
      "3. Recency is critical:\n",
      "   → Churned customers: 875 days since last purchase\n",
      "   → Active customers: 250 days since last purchase\n",
      "\n",
      " ACTIONABLE RECOMMENDATION:\n",
      "----------------------------------------------------------------------\n",
      "  Trigger re-engagement campaigns when:\n",
      "  • Recency > 30 days AND\n",
      "  • Email open rate drops below 20%\n",
      "  This catches customers BEFORE they fully churn\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'coefficient': model.coef_[0],\n",
    "    'abs_coefficient': np.abs(model.coef_[0])\n",
    "}).sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n TOP 10 MOST IMPORTANT FEATURES FOR CHURN PREDICTION:\")\n",
    "print(\"-\" * 70)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    direction = \"↑ increases\" if row['coefficient'] > 0 else \"↓ decreases\"\n",
    "    print(f\"  {row['feature']:30s} {direction} churn risk (coef: {row['coefficient']:7.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUSINESS INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create risk scores for all test customers\n",
    "test_results = pd.DataFrame({\n",
    "    'customer_id': df.iloc[X_test.index]['customer_id'].values,\n",
    "    'actual_churned': y_test.values,\n",
    "    'predicted_churned': y_pred,\n",
    "    'churn_probability': y_pred_proba,\n",
    "    'recency_days': X_test['recency_days'].values,\n",
    "    'email_open_rate': X_test['email_open_rate'].values,\n",
    "    'frequency': X_test['frequency'].values\n",
    "})\n",
    "\n",
    "# Sort by churn probability\n",
    "test_results = test_results.sort_values('churn_probability', ascending=False)\n",
    "\n",
    "print(\"\\n KEY INSIGHTS:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Top 20% highest risk\n",
    "top_20_pct = int(len(test_results) * 0.20)\n",
    "high_risk_customers = test_results.head(top_20_pct)\n",
    "actual_churn_in_top_20 = high_risk_customers['actual_churned'].mean()\n",
    "\n",
    "print(f\"1. Top 20% of at-risk customers ({top_20_pct} customers):\")\n",
    "print(f\"   → {actual_churn_in_top_20:.1%} actually churned\")\n",
    "print(f\"   → Marketing can focus on these {top_20_pct} customers for retention campaigns\")\n",
    "\n",
    "print(f\"\\n2. Email engagement is a strong predictor:\")\n",
    "avg_email_rate_churned = df[df['churned']==1]['email_open_rate'].mean()\n",
    "avg_email_rate_active = df[df['churned']==0]['email_open_rate'].mean()\n",
    "print(f\"   → Churned customers: {avg_email_rate_churned:.1%} email open rate\")\n",
    "print(f\"   → Active customers: {avg_email_rate_active:.1%} email open rate\")\n",
    "\n",
    "print(f\"\\n3. Recency is critical:\")\n",
    "avg_recency_churned = df[df['churned']==1]['recency_days'].mean()\n",
    "avg_recency_active = df[df['churned']==0]['recency_days'].mean()\n",
    "print(f\"   → Churned customers: {avg_recency_churned:.0f} days since last purchase\")\n",
    "print(f\"   → Active customers: {avg_recency_active:.0f} days since last purchase\")\n",
    "\n",
    "print(\"\\n ACTIONABLE RECOMMENDATION:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"  Trigger re-engagement campaigns when:\")\n",
    "print(\"  • Recency > 30 days AND\")\n",
    "print(\"  • Email open rate drops below 20%\")\n",
    "print(\"  This catches customers BEFORE they fully churn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604efee-85f4-459c-9fdc-eda044469be1",
   "metadata": {},
   "source": [
    "Below is a snapshot of the solution we built. \n",
    "\n",
    "Dataset: 5,000 customers from CDP\n",
    "Features: 12 behavioral and engagement metrics\n",
    "Algorithm: Logistic Regression (interpretable, production-ready)\n",
    "Performance: 85.3% accuracy, 98.7% precision, 0.933 ROC-AUC\n",
    "Business Value: Focus on top 20% at-risk customers (100% precision)\n",
    "Key Insight: Email silence predicts churn 30 days before purchase drops\n",
    "\n",
    "This model transforms reactive marketing into proactive retention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc93fee-4ea8-412c-829a-5a598e6de329",
   "metadata": {},
   "source": [
    "##### What next?\n",
    "\n",
    "We built the solution.  How do we take it to production? \n",
    "\n",
    "Below are some of the steps that should be established to successfully use the solution we built such that it is used by the marketing team to \n",
    "\n",
    "1. DATA PIPELINE AUTOMATION\n",
    "   → Feature engineering needs to run daily\n",
    "   → Integrate with data warehouse (Snowflake, BigQuery, Redshift)\n",
    "   → Set up automated data quality checks\n",
    "\n",
    "2. MODEL DEPLOYMENT\n",
    "   → Deploy via REST API or batch scoring system\n",
    "   → Containerize with Docker for reproducibility\n",
    "   → Version control models (MLflow, W&B)\n",
    "   → Set up monitoring for model drift\n",
    "\n",
    "3. CRM INTEGRATION\n",
    "   → Push churn scores to marketing automation platform (Salesforce, HubSpot)\n",
    "   → Create automated workflows for high-risk segments\n",
    "   → Enable marketing ops to filter by risk score\n",
    "\n",
    "4. DATA GOVERNANCE & COMPLIANCE\n",
    "   → Document feature logic for explainability (GDPR requirement)\n",
    "   → Ensure no PII leakage in model artifacts\n",
    "   → Get legal/compliance sign-off on automated decisions\n",
    "   → Set up audit trails\n",
    "\n",
    "5. BUSINESS VALIDATION\n",
    "   → Run A/B test: intervention group vs control group\n",
    "   → Measure: Did targeted campaigns actually reduce churn?\n",
    "   → Track: Cost per save, retention rate lift, ROI\n",
    "   → Iterate based on feedback loop\n",
    "\n",
    "6. STAKEHOLDER ALIGNMENT\n",
    "   → Marketing needs training on how to use risk scores\n",
    "   → Data engineering needs SLAs for feature freshness\n",
    "   → Finance needs to understand ROI calculation\n",
    "   → Product team owns ongoing model iteration\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5672c-1522-4b95-b488-48f5e7c55eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
